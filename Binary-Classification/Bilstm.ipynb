{
  "cells": [
    {
      "metadata": {
        "id": "VmL_Z-W4wEKi",
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "!pip install seqeval==0.0.5\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFjaBfTzpc-z",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vZOmH4WN42DL",
        "outputId": "10d0f5ef-065b-4be0-e94a-384386625a07"
      },
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting pythainlp\n  Downloading pythainlp-2.2.6-py3-none-any.whl (10.6 MB)\n\u001b[K     |████████████████████████████████| 10.6 MB 4.4 MB/s eta 0:00:01\n\u001b[?25hCollecting python-crfsuite>=0.9.6\n  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n\u001b[K     |████████████████████████████████| 743 kB 26.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tinydb>=3.0\n  Downloading tinydb-4.4.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.7/site-packages (from pythainlp) (2.25.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (1.26.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (3.0.4)\nInstalling collected packages: tinydb, python-crfsuite, pythainlp\nSuccessfully installed pythainlp-2.2.6 python-crfsuite-0.9.7 tinydb-4.4.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "31OaMm4Ym7f2",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers , regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Bidirectional , LSTM, GlobalMaxPool1D , Concatenate, Dropout, Embedding, Flatten, Dropout, Activation, Input, Dense, concatenate, GRU, Conv1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, f1_score, precision_score, recall_score\n",
        "from pythainlp.corpus import thai_stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soJzZJd8O-84",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O6v2wa4XrKZE"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preparation \n"
      ]
    },
    {
      "metadata": {
        "id": "QrMTSJAulv4Z",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def create_article_label(df):\n",
        "    article_label_encoder = LabelEncoder()\n",
        "    prediction_encoded = article_label_encoder.fit_transform(df.article)\n",
        "    df.insert(df.shape[1], 'label',prediction_encoded ) \n",
        "    prediction_decoded = article_label_encoder.inverse_transform(prediction_encoded)\n",
        "    map_dict = dict(zip(prediction_encoded,prediction_decoded))\n",
        "    return df, article_label_encoder,map_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-IQvTJemSxA",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "torts_df = pd.read_pickle('../input/processed-torts/processed_torts20200123.pkl')\n",
        "df, article_label_encoder,map_dict = create_article_label(torts_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fQUn7VSI42DU"
      },
      "cell_type": "code",
      "source": [
        "def clean_stop(lst):\n",
        "    clean_list = []\n",
        "    stop_words = list(thai_stopwords())\n",
        "    return [word for word in lst if word not in stop_words]\n",
        "\n",
        "def load_fasttext_fast(word_index, max_words, embed_size,file_name = \"../input/word-vec-thai/cc.th.300.vec\"):\n",
        "    EMBEDDING_FILE = file_name\n",
        "    emb_mean, emb_std = -0.0033470048, 0.109855264\n",
        "    #125,302 tokenized Thai Wikipedia articles using deepcut model\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
        "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\") as f:       \n",
        "        for line in f:\n",
        "            if len(line) <= 100:\n",
        "                continue\n",
        "            word, vec = line.split(' ', 1)\n",
        "            if word not in word_index:\n",
        "                continue\n",
        "            i = word_index[word]\n",
        "            if i >= max_words:\n",
        "                continue\n",
        "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
        "            if len(embedding_vector) == 300:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1XZAvcHqta-",
        "outputId": "0071db6e-636c-4a03-a6b0-267151a9a8bb",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "X_plaintiff = []\n",
        "X_defendant = []\n",
        "X_both = []\n",
        "Y = []\n",
        "Y_set = []\n",
        "cases = []\n",
        "for case_id in tqdm(df.case_id.unique()):\n",
        "    Y = np.zeros(article_label_encoder.classes_.shape[0])  \n",
        "    rows = df[df['case_id'] == case_id]    \n",
        "    token = ''\n",
        "    for i, row in rows.iterrows(): \n",
        "        Y[row.label] = 1 \n",
        "        plaintiff_fact_token = row.plaintiff_fact_token\n",
        "        defendant_fact_token = row.defendant_fact_token   \n",
        "    cases.append(case_id)\n",
        "    X_plaintiff.append(' '.join(clean_stop(plaintiff_fact_token))) \n",
        "    X_defendant.append(' '.join(clean_stop(defendant_fact_token)))\n",
        "    X_both.append([' '.join(clean_stop((plaintiff_fact_token))),  ' '.join(clean_stop(defendant_fact_token))]) \n",
        "    Y_set.append(Y)\n",
        "Y_set = np.array(Y_set)\n",
        "X_both = np.array(X_both)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 2352/2352 [00:23<00:00, 98.72it/s] \n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "V1Hw663J42DX"
      },
      "cell_type": "code",
      "source": [
        "X_both[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RF-fQPgLrgX3",
        "outputId": "0c03b14d-7ec5-48a4-b869-b09ffe122c8d",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "freqs = np.zeros(Y_set.shape[1])\n",
        "for col_idx in np.arange(0, Y_set.shape[1]):\n",
        "    freq = np.sum(Y_set[:, col_idx])\n",
        "    freqs[col_idx] = freq\n",
        "sorted_idx = np.argsort(freqs, axis=0)[::-1]\n",
        "sorted_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([ 687,  251,  692, ..., 1015, 1016,    0])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "imz3kH_hMCLo",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "for idx in sorted_idx[1:11]:\n",
        "  print(f\"{idx} : \" + map_dict[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cwjXjY-Fwl2",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.groupby(['article','label']).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiWtfKIIsZ2r",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "def process_input(num_words, X_train, X_test, X_dev):\n",
        "    strings = '1234567890๑๒๓๔๕๖๗๘๙๐' + string.punctuation\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, oov_token='<UNK>',filters = strings ) \n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "    #convert text data to numerical indexes\n",
        "    train_seqs = tokenizer.texts_to_sequences(X_train)\n",
        "    dev_seqs = tokenizer.texts_to_sequences(X_dev)\n",
        "    test_seqs = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "    max_sequnce_len = max([len(x) for x in train_seqs])\n",
        "\n",
        "    train_seqs = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, maxlen=max_sequnce_len, padding=\"post\")\n",
        "    test_seqs=tf.keras.preprocessing.sequence.pad_sequences(test_seqs, maxlen=max_sequnce_len, padding=\"post\")\n",
        "    dev_seqs=tf.keras.preprocessing.sequence.pad_sequences(dev_seqs, maxlen=max_sequnce_len, padding=\"post\")\n",
        "\n",
        "    return  train_seqs, test_seqs, dev_seqs, max_sequnce_len, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbNrIvhdzM7E",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def proportional_generator(data, label, p=[0.1, 0.9], batch_size=128):\n",
        "    # p indicate number of class and sampling prob\n",
        "   \n",
        "    while (True):\n",
        "        batch_data = []\n",
        "        batch_label = []\n",
        "        sample_id = np.random.choice(len(p), batch_size, p=p) #genearate sample id โดยให้มีโอกาสได้ 1 เยอะๆคือ 0.9 (len(p) คือสุ่มเลข 0-1) ขนาด 128 ตัว\n",
        "        query_idx = [\n",
        "            np.where(label == class_id)[0] for class_id in range(len(p))\n",
        "        ]\n",
        "        for class_id in sample_id:\n",
        "            query_id = np.random.choice(query_idx[class_id], 1)[0]\n",
        "            batch_data.append(data[query_id])\n",
        "            batch_label.append(label[query_id])\n",
        "       \n",
        "        yield np.array(batch_data), np.array(batch_label)\n",
        "     \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "H71YZi0y42DZ"
      },
      "cell_type": "code",
      "source": [
        "def multi_input_proportional_generator(datasets,\n",
        "                                       label,\n",
        "                                       p=[0.1, 0.9],\n",
        "                                       batch_size=128):\n",
        "    # p indicate number of class and sampling prob\n",
        "    while (True):\n",
        "        batch_data = [[], []]\n",
        "        batch_label = []\n",
        "        sample_id = np.random.choice(len(p), batch_size, p=p)\n",
        "        query_idx = [\n",
        "            np.where(label == class_id)[0] for class_id in range(len(p))\n",
        "        ]\n",
        "        for class_id in sample_id:\n",
        "            query_id = np.random.choice(query_idx[class_id], 1)[0]\n",
        "            batch_data[0].append(datasets[0][query_id])\n",
        "            batch_data[1].append(datasets[1][query_id])\n",
        "            batch_label.append(label[query_id])\n",
        "        batch_data[0] = np.array(batch_data[0])\n",
        "        batch_data[1] = np.array(batch_data[1])\n",
        "        yield batch_data, np.array(batch_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSZO7wBJzhq0",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "len(df.case_id.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation functions"
      ],
      "metadata": {
        "id": "VddrCKgs6fPC"
      }
    },
    {
      "metadata": {
        "id": "MDqcH1IN5YH4",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def microf1(y_true, y_pred):\n",
        "\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def macrof1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "def single_class_accuracy(interesting_class_id):\n",
        "    def single_class(y_true, y_pred):\n",
        "        class_id_preds = K.argmax(y_pred, axis=-1)\n",
        "        # Replace class_id_preds with class_id_true for recall here\n",
        "        positive_mask = K.cast(K.equal(class_id_preds, interesting_class_id), 'int32')\n",
        "        true_mask = K.cast(K.equal(y_true, interesting_class_id), 'int32')\n",
        "        acc_mask = K.cast(K.equal(positive_mask, true_mask), 'float32')\n",
        "        class_acc = K.mean(acc_mask)\n",
        "        return class_acc\n",
        "\n",
        "    return single_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bMyDzSh2r8SA"
      },
      "cell_type": "markdown",
      "source": [
        "Training BiLSTM\n",
        "==============="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*One input : Only plaintiff*"
      ],
      "metadata": {
        "id": "yscNHhod8quW"
      }
    },
    {
      "metadata": {
        "id": "6yIIbaICaoWl",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE= 64 \n",
        "EPOCHS = 10\n",
        "NUM_WORDS=8000\n",
        "embedding_size = 300\n",
        " \n",
        "for f_num in sorted_idx[1:11]:  \n",
        "    print(f'<<<<<<label {f_num}>>>>>>>>' )\n",
        "    X = X_both\n",
        "    Y = Y_set[:, f_num].astype(int)\n",
        "  \n",
        "    X_train, X_rest, Y_train, Y_rest = train_test_split(X, Y, test_size=0.3, random_state=42)    \n",
        "    X_test, X_dev, Y_test, Y_dev = train_test_split(X_rest, Y_rest, test_size=0.5, random_state=42)  \n",
        " \n",
        "    train_seqs, test_seqs, dev_seqs, max_sequnce_len, tokenizer = process_input(NUM_WORDS, X_train[:, 0], X_test[:, 0],X_dev[:, 0])\n",
        "    embedding_matrix =  load_fasttext_fast(tokenizer.word_index,NUM_WORDS+1,embedding_size) #load word embedding\n",
        "    \n",
        "    train_generator = proportional_generator(train_seqs, Y_train, p=[0.5, 0.5], batch_size=BATCH_SIZE)\n",
        "    validation_generator = proportional_generator(dev_seqs, Y_dev, batch_size=BATCH_SIZE)\n",
        " \n",
        "    input_layer = Input(shape=(max_sequnce_len,))\n",
        "    embedding_layer = Embedding(NUM_WORDS+1, embedding_size , weights=[embedding_matrix], trainable= False , mask_zero=True)(input_layer) \n",
        "    model = Bidirectional(LSTM(units=50, recurrent_dropout=0.3))(embedding_layer)\n",
        "    f1 = Dense(50, activation='relu')(model)\n",
        "    d1 = Dropout(.5)(f1)\n",
        "    out = Dense(1, activation='sigmoid')(d1)\n",
        "    model = Model(input_layer, out)\n",
        "    \n",
        "    opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001,\n",
        "    name='Adam'\n",
        "        )\n",
        "    model.compile(optimizer= opt,loss=\"binary_crossentropy\", metrics=['accuracy', tf.keras.metrics.AUC(), recall, precision, microf1, macrof1])\n",
        "    model.summary()\n",
        " \n",
        "    num_batches = int(len(train_seqs)/BATCH_SIZE)\n",
        "    history = model.fit(train_generator, epochs=EPOCHS, steps_per_epoch=num_batches,validation_data=validation_generator,validation_steps=num_batches,verbose = 1)\n",
        "\n",
        "    print(\"Evaluation\")\n",
        "    print(f'<<<<<<label {f_num}>>>>>>>>' )\n",
        "\n",
        "    predictions=model.predict(test_seqs, verbose=1)\n",
        "    y_pred = [1 if lst[0] > 0.5 else 0  for lst in predictions ]\n",
        "    print('f1 : ')\n",
        "    print(f1_score(Y_test, y_pred,labels=[1]))\n",
        "    print('------------------------------------------------------------ ')\n",
        "    print('precision : ')\n",
        "    print(precision_score(Y_test, y_pred,labels=[1]))\n",
        "    print('------------------------------------------------------------ ')\n",
        "    print('recall : ')\n",
        "    print(recall_score(Y_test, y_pred,labels=[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Two inputs : Plaintiff + Defendant*"
      ],
      "metadata": {
        "id": "HSWb2YMB8wTX"
      }
    },
    {
      "metadata": {
        "id": "CmnKROURzB1l",
        "trusted": true,
        "outputId": "328d8a50-ceeb-4747-fa52-fae51462dc88"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "EPOCHS=10\n",
        "NUM_WORDS=8000\n",
        "embedding_size=300\n",
        "\n",
        "for f_num in sorted_idx[4:11]:  \n",
        "    X = X_both\n",
        "    Y = Y_set[:, f_num].astype(int)\n",
        "    X_train, X_rest, Y_train, Y_rest = train_test_split(X, Y, test_size=0.3, random_state=42)    \n",
        "    X_test, X_dev, Y_test, Y_dev = train_test_split(X_rest, Y_rest, test_size=0.5, random_state=42)  \n",
        "    train_seqs1, test_seqs1, dev_seqs1, max_sequence_len1, tokenizer1 = process_input(NUM_WORDS, X_train[:, 0], X_test[:, 0], X_dev[:, 0])\n",
        "    train_seqs2, test_seqs2,dev_seqs2, max_sequence_len2, tokenizer2 = process_input(NUM_WORDS, X_train[:, 1], X_test[:, 1], X_dev[:, 1])\n",
        "    train_generator = multi_input_proportional_generator([train_seqs1, train_seqs2], Y_train, p=[0.5, 0.5], batch_size=BATCH_SIZE)\n",
        "    validation_generator = multi_input_proportional_generator([dev_seqs1, dev_seqs2], Y_dev, batch_size=BATCH_SIZE)\n",
        " \n",
        "    input_layer1 = Input(shape=(max_sequence_len1,))\n",
        "    embedding_layer1 = Embedding(input_dim= NUM_WORDS+1, output_dim=128, input_length= max_sequence_len1, trainable=True)(input_layer1) \n",
        "    Bi_layer1 = Bidirectional(LSTM(units=50, recurrent_dropout=0.3))(embedding_layer1)\n",
        "        \n",
        "    input_layer2 = Input(shape=(max_sequence_len2,))\n",
        "    embedding_layer2 = Embedding(input_dim= NUM_WORDS+1, output_dim=128, input_length=max_sequence_len2, trainable=True)(input_layer2)\n",
        "    Bi_layer2 = Bidirectional(LSTM(units=50, recurrent_dropout=0.3))(embedding_layer2)\n",
        "            \n",
        "    concat_layer = Concatenate()([Bi_layer1, Bi_layer2])\n",
        "    \n",
        "    f1 = Dense(100, activation='relu')(concat_layer)\n",
        "    d1 = Dropout(.5)(f1)\n",
        "    f2 = Dense(100, activation='relu')(d1)\n",
        "    d2 = Dropout(.5)(f2)\n",
        "    out = Dense(1, activation='sigmoid')(d2)\n",
        "    model = Model(inputs=[input_layer1, input_layer2], outputs = out)\n",
        " \n",
        "    opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001,\n",
        "    name='Adam'\n",
        "        )\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[single_class_accuracy(1),tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC(),recall, precision, microf1, macrof1])\n",
        "    model.summary()\n",
        "    \n",
        "    num_batches = int(len(train_seqs1)/BATCH_SIZE)\n",
        " \n",
        "    history = model.fit(train_generator, epochs=EPOCHS, steps_per_epoch=num_batches,validation_data=validation_generator,validation_steps=num_batches,verbose = 1)\n",
        " \n",
        " \n",
        "    print(\"Evaluation\")\n",
        "    print(f'<<<<<<label {f_num}>>>>>>>>' )\n",
        "\n",
        "    predictions=model.predict([test_seqs1,test_seqs2], verbose=1)\n",
        "    y_pred = [1 if lst[0] > 0.5 else 0  for lst in predictions ]\n",
        "    print('f1 : ')\n",
        "    print(f1_score(Y_test, y_pred,labels=[1]))\n",
        "    print('------------------------------------------------------------ ')\n",
        "    print('precision : ')\n",
        "    print(precision_score(Y_test, y_pred,labels=[1]))\n",
        "    print('------------------------------------------------------------ ')\n",
        "    print('recall : ')\n",
        "    print(recall_score(Y_test, y_pred,labels=[1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Model: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_13 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_14 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_12 (Embedding)        (None, 1067, 128)    1024128     input_13[0][0]                   \n__________________________________________________________________________________________________\nembedding_13 (Embedding)        (None, 521, 128)     1024128     input_14[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_12 (Bidirectional (None, 100)          71600       embedding_12[0][0]               \n__________________________________________________________________________________________________\nbidirectional_13 (Bidirectional (None, 100)          71600       embedding_13[0][0]               \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 200)          0           bidirectional_12[0][0]           \n                                                                 bidirectional_13[0][0]           \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 100)          20100       concatenate_5[0][0]              \n__________________________________________________________________________________________________\ndropout_10 (Dropout)            (None, 100)          0           dense_15[0][0]                   \n__________________________________________________________________________________________________\ndense_16 (Dense)                (None, 100)          10100       dropout_10[0][0]                 \n__________________________________________________________________________________________________\ndropout_11 (Dropout)            (None, 100)          0           dense_16[0][0]                   \n__________________________________________________________________________________________________\ndense_17 (Dense)                (None, 1)            101         dropout_11[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 93s 3s/step - loss: 0.6920 - single_class: 0.5116 - binary_accuracy: 0.5292 - auc_4: 0.5359 - recall: 0.5420 - precision: 0.5130 - microf1: 0.5243 - macrof1: 0.5243 - val_loss: 0.6947 - val_single_class: 0.1131 - val_binary_accuracy: 0.3744 - val_auc_4: 0.6149 - val_recall: 0.3251 - val_precision: 0.9200 - val_microf1: 0.4773 - val_macrof1: 0.4773\nEpoch 2/10\n25/25 [==============================] - 79s 3s/step - loss: 0.6924 - single_class: 0.4857 - binary_accuracy: 0.5142 - auc_4: 0.5307 - recall: 0.4803 - precision: 0.5394 - microf1: 0.4985 - macrof1: 0.4985 - val_loss: 0.6889 - val_single_class: 0.0906 - val_binary_accuracy: 0.7375 - val_auc_4: 0.6123 - val_recall: 0.7667 - val_precision: 0.9339 - val_microf1: 0.8406 - val_macrof1: 0.8406\nEpoch 3/10\n25/25 [==============================] - 78s 3s/step - loss: 0.6920 - single_class: 0.4786 - binary_accuracy: 0.5156 - auc_4: 0.5242 - recall: 0.6062 - precision: 0.5317 - microf1: 0.5637 - macrof1: 0.5637 - val_loss: 0.6867 - val_single_class: 0.1094 - val_binary_accuracy: 0.8181 - val_auc_4: 0.6396 - val_recall: 0.8781 - val_precision: 0.9147 - val_microf1: 0.8954 - val_macrof1: 0.8954\nEpoch 4/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6902 - single_class: 0.4856 - binary_accuracy: 0.5690 - auc_4: 0.5633 - recall: 0.6899 - precision: 0.5654 - microf1: 0.6183 - macrof1: 0.6183 - val_loss: 0.6819 - val_single_class: 0.1025 - val_binary_accuracy: 0.8669 - val_auc_4: 0.6946 - val_recall: 0.9428 - val_precision: 0.9118 - val_microf1: 0.9266 - val_macrof1: 0.9266\nEpoch 5/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6899 - single_class: 0.4788 - binary_accuracy: 0.5630 - auc_4: 0.5736 - recall: 0.7251 - precision: 0.5608 - microf1: 0.6303 - macrof1: 0.6303 - val_loss: 0.6828 - val_single_class: 0.0913 - val_binary_accuracy: 0.8425 - val_auc_4: 0.6286 - val_recall: 0.9061 - val_precision: 0.9199 - val_microf1: 0.9121 - val_macrof1: 0.9121\nEpoch 6/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6869 - single_class: 0.4778 - binary_accuracy: 0.5817 - auc_4: 0.6207 - recall: 0.7587 - precision: 0.5770 - microf1: 0.6528 - macrof1: 0.6528 - val_loss: 0.6859 - val_single_class: 0.1063 - val_binary_accuracy: 0.6463 - val_auc_4: 0.6540 - val_recall: 0.6596 - val_precision: 0.9225 - val_microf1: 0.7682 - val_macrof1: 0.7682\nEpoch 7/10\n25/25 [==============================] - 79s 3s/step - loss: 0.6819 - single_class: 0.5384 - binary_accuracy: 0.6191 - auc_4: 0.6741 - recall: 0.5787 - precision: 0.6059 - microf1: 0.5815 - macrof1: 0.5815 - val_loss: 0.7283 - val_single_class: 0.1056 - val_binary_accuracy: 0.2000 - val_auc_4: 0.5891 - val_recall: 0.1110 - val_precision: 0.9525 - val_microf1: 0.1977 - val_macrof1: 0.1977\nEpoch 8/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6627 - single_class: 0.4982 - binary_accuracy: 0.7120 - auc_4: 0.7682 - recall: 0.6073 - precision: 0.7791 - microf1: 0.6736 - macrof1: 0.6736 - val_loss: 0.7291 - val_single_class: 0.0944 - val_binary_accuracy: 0.3988 - val_auc_4: 0.6637 - val_recall: 0.3570 - val_precision: 0.9443 - val_microf1: 0.5157 - val_macrof1: 0.5157\nEpoch 9/10\n25/25 [==============================] - 80s 3s/step - loss: 0.6008 - single_class: 0.5104 - binary_accuracy: 0.7868 - auc_4: 0.8215 - recall: 0.7665 - precision: 0.8079 - microf1: 0.7801 - macrof1: 0.7801 - val_loss: 0.7797 - val_single_class: 0.1150 - val_binary_accuracy: 0.3356 - val_auc_4: 0.6614 - val_recall: 0.2762 - val_precision: 0.9076 - val_microf1: 0.4219 - val_macrof1: 0.4219\nEpoch 10/10\n25/25 [==============================] - 81s 3s/step - loss: 0.4750 - single_class: 0.5002 - binary_accuracy: 0.8721 - auc_4: 0.9167 - recall: 0.8432 - precision: 0.8921 - microf1: 0.8650 - macrof1: 0.8650 - val_loss: 0.8465 - val_single_class: 0.1044 - val_binary_accuracy: 0.3856 - val_auc_4: 0.6897 - val_recall: 0.3360 - val_precision: 0.9406 - val_microf1: 0.4916 - val_macrof1: 0.4916\nEvaluation\n<<<<<<label 154>>>>>>>>\n12/12 [==============================] - 4s 293ms/step\nf1 : \n0.37113402061855666\n------------------------------------------------------------ \nprecision : \n0.2857142857142857\n------------------------------------------------------------ \nrecall : \n0.5294117647058824\nModel: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_15 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_16 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_14 (Embedding)        (None, 1067, 128)    1024128     input_15[0][0]                   \n__________________________________________________________________________________________________\nembedding_15 (Embedding)        (None, 521, 128)     1024128     input_16[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_14 (Bidirectional (None, 100)          71600       embedding_14[0][0]               \n__________________________________________________________________________________________________\nbidirectional_15 (Bidirectional (None, 100)          71600       embedding_15[0][0]               \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 200)          0           bidirectional_14[0][0]           \n                                                                 bidirectional_15[0][0]           \n__________________________________________________________________________________________________\ndense_18 (Dense)                (None, 100)          20100       concatenate_6[0][0]              \n__________________________________________________________________________________________________\ndropout_12 (Dropout)            (None, 100)          0           dense_18[0][0]                   \n__________________________________________________________________________________________________\ndense_19 (Dense)                (None, 100)          10100       dropout_12[0][0]                 \n__________________________________________________________________________________________________\ndropout_13 (Dropout)            (None, 100)          0           dense_19[0][0]                   \n__________________________________________________________________________________________________\ndense_20 (Dense)                (None, 1)            101         dropout_13[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "25/25 [==============================] - 89s 3s/step - loss: 0.6924 - single_class: 0.4771 - binary_accuracy: 0.5027 - auc_5: 0.5447 - recall: 0.3102 - precision: 0.5559 - microf1: 0.3871 - macrof1: 0.3871 - val_loss: 0.6911 - val_single_class: 0.0981 - val_binary_accuracy: 0.6744 - val_auc_5: 0.5063 - val_recall: 0.7157 - val_precision: 0.9017 - val_microf1: 0.7966 - val_macrof1: 0.7966\nEpoch 2/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6921 - single_class: 0.4832 - binary_accuracy: 0.5323 - auc_5: 0.5428 - recall: 0.5514 - precision: 0.5432 - microf1: 0.5453 - macrof1: 0.5453 - val_loss: 0.6856 - val_single_class: 0.1006 - val_binary_accuracy: 0.8631 - val_auc_5: 0.4660 - val_recall: 0.9580 - val_precision: 0.8975 - val_microf1: 0.9261 - val_macrof1: 0.9261\nEpoch 3/10\n25/25 [==============================] - 75s 3s/step - loss: 0.6920 - single_class: 0.4867 - binary_accuracy: 0.5181 - auc_5: 0.5251 - recall: 0.6290 - precision: 0.5259 - microf1: 0.5711 - macrof1: 0.5711 - val_loss: 0.6865 - val_single_class: 0.1000 - val_binary_accuracy: 0.8056 - val_auc_5: 0.4744 - val_recall: 0.8850 - val_precision: 0.8982 - val_microf1: 0.8907 - val_macrof1: 0.8907\nEpoch 4/10\n25/25 [==============================] - 74s 3s/step - loss: 0.6910 - single_class: 0.4897 - binary_accuracy: 0.5352 - auc_5: 0.5485 - recall: 0.5865 - precision: 0.5429 - microf1: 0.5577 - macrof1: 0.5577 - val_loss: 0.6899 - val_single_class: 0.0950 - val_binary_accuracy: 0.7031 - val_auc_5: 0.5327 - val_recall: 0.7470 - val_precision: 0.9079 - val_microf1: 0.8184 - val_macrof1: 0.8184\nEpoch 5/10\n25/25 [==============================] - 74s 3s/step - loss: 0.6905 - single_class: 0.4851 - binary_accuracy: 0.5345 - auc_5: 0.5544 - recall: 0.5647 - precision: 0.5469 - microf1: 0.5534 - macrof1: 0.5534 - val_loss: 0.6916 - val_single_class: 0.1169 - val_binary_accuracy: 0.6513 - val_auc_5: 0.5008 - val_recall: 0.6787 - val_precision: 0.8996 - val_microf1: 0.7726 - val_macrof1: 0.7726\nEpoch 6/10\n25/25 [==============================] - 73s 3s/step - loss: 0.6879 - single_class: 0.5114 - binary_accuracy: 0.5691 - auc_5: 0.6046 - recall: 0.6774 - precision: 0.5448 - microf1: 0.5978 - macrof1: 0.5978 - val_loss: 0.7049 - val_single_class: 0.1037 - val_binary_accuracy: 0.3681 - val_auc_5: 0.5134 - val_recall: 0.3237 - val_precision: 0.9186 - val_microf1: 0.4745 - val_macrof1: 0.4745\nEpoch 7/10\n25/25 [==============================] - 74s 3s/step - loss: 0.6755 - single_class: 0.5207 - binary_accuracy: 0.6518 - auc_5: 0.7338 - recall: 0.5677 - precision: 0.6664 - microf1: 0.6069 - macrof1: 0.6069 - val_loss: 0.7357 - val_single_class: 0.0988 - val_binary_accuracy: 0.3088 - val_auc_5: 0.5277 - val_recall: 0.2516 - val_precision: 0.9359 - val_microf1: 0.3931 - val_macrof1: 0.3931\nEpoch 8/10\n25/25 [==============================] - 75s 3s/step - loss: 0.6461 - single_class: 0.4743 - binary_accuracy: 0.7284 - auc_5: 0.7879 - recall: 0.6825 - precision: 0.7804 - microf1: 0.7241 - macrof1: 0.7241 - val_loss: 0.8502 - val_single_class: 0.1031 - val_binary_accuracy: 0.2769 - val_auc_5: 0.5477 - val_recall: 0.2005 - val_precision: 0.9657 - val_microf1: 0.3288 - val_macrof1: 0.3288\nEpoch 9/10\n25/25 [==============================] - 78s 3s/step - loss: 0.5306 - single_class: 0.5109 - binary_accuracy: 0.8197 - auc_5: 0.8833 - recall: 0.7387 - precision: 0.8729 - microf1: 0.7964 - macrof1: 0.7964 - val_loss: 1.0575 - val_single_class: 0.1013 - val_binary_accuracy: 0.2494 - val_auc_5: 0.5896 - val_recall: 0.1684 - val_precision: 0.9742 - val_microf1: 0.2841 - val_macrof1: 0.2841\nEpoch 10/10\n25/25 [==============================] - 77s 3s/step - loss: 0.3831 - single_class: 0.5131 - binary_accuracy: 0.8876 - auc_5: 0.9462 - recall: 0.8371 - precision: 0.9258 - microf1: 0.8777 - macrof1: 0.8777 - val_loss: 1.3251 - val_single_class: 0.1000 - val_binary_accuracy: 0.2519 - val_auc_5: 0.5153 - val_recall: 0.1831 - val_precision: 0.9162 - val_microf1: 0.3017 - val_macrof1: 0.3017\nEvaluation\n<<<<<<label 135>>>>>>>>\n12/12 [==============================] - 4s 288ms/step\nf1 : \n0.12820512820512822\n------------------------------------------------------------ \nprecision : \n0.08928571428571429\n------------------------------------------------------------ \nrecall : \n0.22727272727272727\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_17 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_18 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_16 (Embedding)        (None, 1067, 128)    1024128     input_17[0][0]                   \n__________________________________________________________________________________________________\nembedding_17 (Embedding)        (None, 521, 128)     1024128     input_18[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_16 (Bidirectional (None, 100)          71600       embedding_16[0][0]               \n__________________________________________________________________________________________________\nbidirectional_17 (Bidirectional (None, 100)          71600       embedding_17[0][0]               \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 200)          0           bidirectional_16[0][0]           \n                                                                 bidirectional_17[0][0]           \n__________________________________________________________________________________________________\ndense_21 (Dense)                (None, 100)          20100       concatenate_7[0][0]              \n__________________________________________________________________________________________________\ndropout_14 (Dropout)            (None, 100)          0           dense_21[0][0]                   \n__________________________________________________________________________________________________\ndense_22 (Dense)                (None, 100)          10100       dropout_14[0][0]                 \n__________________________________________________________________________________________________\ndropout_15 (Dropout)            (None, 100)          0           dense_22[0][0]                   \n__________________________________________________________________________________________________\ndense_23 (Dense)                (None, 1)            101         dropout_15[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 89s 3s/step - loss: 0.6926 - single_class: 0.4959 - binary_accuracy: 0.5032 - auc_6: 0.5244 - recall: 0.6415 - precision: 0.5062 - microf1: 0.5625 - macrof1: 0.5625 - val_loss: 0.6897 - val_single_class: 0.0981 - val_binary_accuracy: 0.9038 - val_auc_6: 0.4650 - val_recall: 1.0000 - val_precision: 0.9036 - val_microf1: 0.9489 - val_macrof1: 0.9489\nEpoch 2/10\n25/25 [==============================] - 78s 3s/step - loss: 0.6928 - single_class: 0.5138 - binary_accuracy: 0.5128 - auc_6: 0.5259 - recall: 0.6579 - precision: 0.4988 - microf1: 0.5648 - macrof1: 0.5648 - val_loss: 0.6896 - val_single_class: 0.0919 - val_binary_accuracy: 0.9181 - val_auc_6: 0.5450 - val_recall: 1.0000 - val_precision: 0.9174 - val_microf1: 0.9567 - val_macrof1: 0.9567\nEpoch 3/10\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "25/25 [==============================] - 78s 3s/step - loss: 0.6930 - single_class: 0.5150 - binary_accuracy: 0.5175 - auc_6: 0.5129 - recall: 0.6014 - precision: 0.5036 - microf1: 0.5426 - macrof1: 0.5426 - val_loss: 0.6881 - val_single_class: 0.0950 - val_binary_accuracy: 0.9137 - val_auc_6: 0.6414 - val_recall: 1.0000 - val_precision: 0.9129 - val_microf1: 0.9542 - val_macrof1: 0.9542\nEpoch 4/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6908 - single_class: 0.5114 - binary_accuracy: 0.5704 - auc_6: 0.5883 - recall: 0.7530 - precision: 0.5455 - microf1: 0.6300 - macrof1: 0.6300 - val_loss: 0.6826 - val_single_class: 0.1169 - val_binary_accuracy: 0.8925 - val_auc_6: 0.7015 - val_recall: 1.0000 - val_precision: 0.8913 - val_microf1: 0.9421 - val_macrof1: 0.9421\nEpoch 5/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6895 - single_class: 0.5071 - binary_accuracy: 0.5417 - auc_6: 0.6044 - recall: 0.8062 - precision: 0.5221 - microf1: 0.6320 - macrof1: 0.6320 - val_loss: 0.6753 - val_single_class: 0.0944 - val_binary_accuracy: 0.9150 - val_auc_6: 0.7295 - val_recall: 1.0000 - val_precision: 0.9142 - val_microf1: 0.9548 - val_macrof1: 0.9548\nEpoch 6/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6873 - single_class: 0.5176 - binary_accuracy: 0.5799 - auc_6: 0.6559 - recall: 0.8428 - precision: 0.5477 - microf1: 0.6561 - macrof1: 0.6561 - val_loss: 0.6888 - val_single_class: 0.0950 - val_binary_accuracy: 0.5525 - val_auc_6: 0.6782 - val_recall: 0.5378 - val_precision: 0.9420 - val_microf1: 0.6834 - val_macrof1: 0.6834\nEpoch 7/10\n25/25 [==============================] - 79s 3s/step - loss: 0.6724 - single_class: 0.4842 - binary_accuracy: 0.7014 - auc_6: 0.7892 - recall: 0.8241 - precision: 0.6731 - microf1: 0.7363 - macrof1: 0.7363 - val_loss: 0.6994 - val_single_class: 0.1119 - val_binary_accuracy: 0.4375 - val_auc_6: 0.6949 - val_recall: 0.3795 - val_precision: 0.9683 - val_microf1: 0.5420 - val_macrof1: 0.5420\nEpoch 8/10\n25/25 [==============================] - 78s 3s/step - loss: 0.6118 - single_class: 0.4794 - binary_accuracy: 0.7724 - auc_6: 0.8613 - recall: 0.8173 - precision: 0.7671 - microf1: 0.7854 - macrof1: 0.7854 - val_loss: 0.7227 - val_single_class: 0.0988 - val_binary_accuracy: 0.4206 - val_auc_6: 0.7149 - val_recall: 0.3709 - val_precision: 0.9651 - val_microf1: 0.5321 - val_macrof1: 0.5321\nEpoch 9/10\n25/25 [==============================] - 78s 3s/step - loss: 0.4929 - single_class: 0.4998 - binary_accuracy: 0.8373 - auc_6: 0.9037 - recall: 0.8021 - precision: 0.8666 - microf1: 0.8306 - macrof1: 0.8306 - val_loss: 1.1445 - val_single_class: 0.0969 - val_binary_accuracy: 0.2256 - val_auc_6: 0.7160 - val_recall: 0.1428 - val_precision: 0.9964 - val_microf1: 0.2485 - val_macrof1: 0.2485\nEpoch 10/10\n25/25 [==============================] - 78s 3s/step - loss: 0.3734 - single_class: 0.4898 - binary_accuracy: 0.8549 - auc_6: 0.9244 - recall: 0.7769 - precision: 0.9302 - microf1: 0.8451 - macrof1: 0.8451 - val_loss: 1.0744 - val_single_class: 0.1037 - val_binary_accuracy: 0.3350 - val_auc_6: 0.6776 - val_recall: 0.2620 - val_precision: 0.9838 - val_microf1: 0.4109 - val_macrof1: 0.4109\nEvaluation\n<<<<<<label 715>>>>>>>>\n12/12 [==============================] - 4s 289ms/step\nf1 : \n0.3333333333333333\n------------------------------------------------------------ \nprecision : \n0.32\n------------------------------------------------------------ \nrecall : \n0.34782608695652173\nModel: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_19 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_20 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_18 (Embedding)        (None, 1067, 128)    1024128     input_19[0][0]                   \n__________________________________________________________________________________________________\nembedding_19 (Embedding)        (None, 521, 128)     1024128     input_20[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_18 (Bidirectional (None, 100)          71600       embedding_18[0][0]               \n__________________________________________________________________________________________________\nbidirectional_19 (Bidirectional (None, 100)          71600       embedding_19[0][0]               \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 200)          0           bidirectional_18[0][0]           \n                                                                 bidirectional_19[0][0]           \n__________________________________________________________________________________________________\ndense_24 (Dense)                (None, 100)          20100       concatenate_8[0][0]              \n__________________________________________________________________________________________________\ndropout_16 (Dropout)            (None, 100)          0           dense_24[0][0]                   \n__________________________________________________________________________________________________\ndense_25 (Dense)                (None, 100)          10100       dropout_16[0][0]                 \n__________________________________________________________________________________________________\ndropout_17 (Dropout)            (None, 100)          0           dense_25[0][0]                   \n__________________________________________________________________________________________________\ndense_26 (Dense)                (None, 1)            101         dropout_17[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 106s 4s/step - loss: 0.6928 - single_class: 0.5045 - binary_accuracy: 0.5157 - auc_7: 0.5210 - recall: 0.2698 - precision: 0.5199 - microf1: 0.3512 - macrof1: 0.3512 - val_loss: 0.6981 - val_single_class: 0.0969 - val_binary_accuracy: 0.1331 - val_auc_7: 0.6176 - val_recall: 0.0403 - val_precision: 0.8000 - val_microf1: 0.0759 - val_macrof1: 0.0759\nEpoch 2/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6935 - single_class: 0.4818 - binary_accuracy: 0.5107 - auc_7: 0.5093 - recall: 0.4412 - precision: 0.5350 - microf1: 0.4757 - macrof1: 0.4757 - val_loss: 0.6909 - val_single_class: 0.0906 - val_binary_accuracy: 0.7987 - val_auc_7: 0.5719 - val_recall: 0.8300 - val_precision: 0.9422 - val_microf1: 0.8816 - val_macrof1: 0.8816\nEpoch 3/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6914 - single_class: 0.5060 - binary_accuracy: 0.5271 - auc_7: 0.5575 - recall: 0.5410 - precision: 0.5224 - microf1: 0.5255 - macrof1: 0.5255 - val_loss: 0.6856 - val_single_class: 0.0819 - val_binary_accuracy: 0.7744 - val_auc_7: 0.6314 - val_recall: 0.8092 - val_precision: 0.9366 - val_microf1: 0.8671 - val_macrof1: 0.8671\nEpoch 4/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6889 - single_class: 0.4982 - binary_accuracy: 0.5856 - auc_7: 0.6248 - recall: 0.6637 - precision: 0.5754 - microf1: 0.6137 - macrof1: 0.6137 - val_loss: 0.6896 - val_single_class: 0.0969 - val_binary_accuracy: 0.7513 - val_auc_7: 0.6512 - val_recall: 0.7779 - val_precision: 0.9361 - val_microf1: 0.8484 - val_macrof1: 0.8484\nEpoch 5/10\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "25/25 [==============================] - 79s 3s/step - loss: 0.6851 - single_class: 0.4991 - binary_accuracy: 0.6358 - auc_7: 0.6658 - recall: 0.5989 - precision: 0.6486 - microf1: 0.6194 - macrof1: 0.6194 - val_loss: 0.6929 - val_single_class: 0.0856 - val_binary_accuracy: 0.6750 - val_auc_7: 0.6731 - val_recall: 0.6777 - val_precision: 0.9546 - val_microf1: 0.7905 - val_macrof1: 0.7905\nEpoch 6/10\n25/25 [==============================] - 79s 3s/step - loss: 0.6691 - single_class: 0.5165 - binary_accuracy: 0.7000 - auc_7: 0.7625 - recall: 0.6305 - precision: 0.7243 - microf1: 0.6706 - macrof1: 0.6706 - val_loss: 0.7376 - val_single_class: 0.0969 - val_binary_accuracy: 0.3094 - val_auc_7: 0.7428 - val_recall: 0.2404 - val_precision: 0.9800 - val_microf1: 0.3843 - val_macrof1: 0.3843\nEpoch 7/10\n25/25 [==============================] - 80s 3s/step - loss: 0.6066 - single_class: 0.5006 - binary_accuracy: 0.7887 - auc_7: 0.8799 - recall: 0.6482 - precision: 0.8995 - microf1: 0.7504 - macrof1: 0.7504 - val_loss: 0.8112 - val_single_class: 0.0988 - val_binary_accuracy: 0.4031 - val_auc_7: 0.7350 - val_recall: 0.3565 - val_precision: 0.9481 - val_microf1: 0.5147 - val_macrof1: 0.5147\nEpoch 8/10\n25/25 [==============================] - 80s 3s/step - loss: 0.4609 - single_class: 0.5209 - binary_accuracy: 0.8651 - auc_7: 0.9235 - recall: 0.8452 - precision: 0.8696 - microf1: 0.8560 - macrof1: 0.8560 - val_loss: 1.1514 - val_single_class: 0.1200 - val_binary_accuracy: 0.1981 - val_auc_7: 0.7772 - val_recall: 0.0945 - val_precision: 0.9447 - val_microf1: 0.1707 - val_macrof1: 0.1707\nEpoch 9/10\n25/25 [==============================] - 89s 3s/step - loss: 0.2765 - single_class: 0.5254 - binary_accuracy: 0.9248 - auc_7: 0.9699 - recall: 0.9149 - precision: 0.9232 - microf1: 0.9178 - macrof1: 0.9178 - val_loss: 1.4120 - val_single_class: 0.1069 - val_binary_accuracy: 0.3406 - val_auc_7: 0.7499 - val_recall: 0.2695 - val_precision: 0.9718 - val_microf1: 0.4188 - val_macrof1: 0.4188\nEpoch 10/10\n25/25 [==============================] - 76s 3s/step - loss: 0.1665 - single_class: 0.4760 - binary_accuracy: 0.9532 - auc_7: 0.9911 - recall: 0.9534 - precision: 0.9594 - microf1: 0.9558 - macrof1: 0.9558 - val_loss: 2.0803 - val_single_class: 0.1088 - val_binary_accuracy: 0.2256 - val_auc_7: 0.7350 - val_recall: 0.1348 - val_precision: 0.9738 - val_microf1: 0.2347 - val_macrof1: 0.2347\nEvaluation\n<<<<<<label 688>>>>>>>>\n12/12 [==============================] - 4s 275ms/step\nf1 : \n0.2608695652173913\n------------------------------------------------------------ \nprecision : \n0.3\n------------------------------------------------------------ \nrecall : \n0.23076923076923078\nModel: \"model_9\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_21 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_22 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_20 (Embedding)        (None, 1067, 128)    1024128     input_21[0][0]                   \n__________________________________________________________________________________________________\nembedding_21 (Embedding)        (None, 521, 128)     1024128     input_22[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_20 (Bidirectional (None, 100)          71600       embedding_20[0][0]               \n__________________________________________________________________________________________________\nbidirectional_21 (Bidirectional (None, 100)          71600       embedding_21[0][0]               \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 200)          0           bidirectional_20[0][0]           \n                                                                 bidirectional_21[0][0]           \n__________________________________________________________________________________________________\ndense_27 (Dense)                (None, 100)          20100       concatenate_9[0][0]              \n__________________________________________________________________________________________________\ndropout_18 (Dropout)            (None, 100)          0           dense_27[0][0]                   \n__________________________________________________________________________________________________\ndense_28 (Dense)                (None, 100)          10100       dropout_18[0][0]                 \n__________________________________________________________________________________________________\ndropout_19 (Dropout)            (None, 100)          0           dense_28[0][0]                   \n__________________________________________________________________________________________________\ndense_29 (Dense)                (None, 1)            101         dropout_19[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 84s 3s/step - loss: 0.6944 - single_class: 0.5360 - binary_accuracy: 0.4674 - auc_8: 0.4690 - recall: 0.6976 - precision: 0.4524 - microf1: 0.5429 - macrof1: 0.5429 - val_loss: 0.6974 - val_single_class: 0.0950 - val_binary_accuracy: 0.0950 - val_auc_8: 0.6329 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_microf1: 0.0000e+00 - val_macrof1: 0.0000e+00\nEpoch 2/10\n25/25 [==============================] - 75s 3s/step - loss: 0.6931 - single_class: 0.4774 - binary_accuracy: 0.4951 - auc_8: 0.4990 - recall: 0.4949 - precision: 0.5202 - microf1: 0.5028 - macrof1: 0.5028 - val_loss: 0.6934 - val_single_class: 0.1050 - val_binary_accuracy: 0.5700 - val_auc_8: 0.6425 - val_recall: 0.5352 - val_precision: 0.9714 - val_microf1: 0.6875 - val_macrof1: 0.6875\nEpoch 3/10\n25/25 [==============================] - 75s 3s/step - loss: 0.6926 - single_class: 0.4770 - binary_accuracy: 0.5096 - auc_8: 0.5175 - recall: 0.6193 - precision: 0.5256 - microf1: 0.5643 - macrof1: 0.5643 - val_loss: 0.6869 - val_single_class: 0.0950 - val_binary_accuracy: 0.8612 - val_auc_8: 0.6968 - val_recall: 0.9178 - val_precision: 0.9269 - val_microf1: 0.9219 - val_macrof1: 0.9219\nEpoch 4/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6914 - single_class: 0.5005 - binary_accuracy: 0.5372 - auc_8: 0.5591 - recall: 0.7950 - precision: 0.5232 - microf1: 0.6286 - macrof1: 0.6286 - val_loss: 0.6817 - val_single_class: 0.0931 - val_binary_accuracy: 0.8644 - val_auc_8: 0.7585 - val_recall: 0.9101 - val_precision: 0.9380 - val_microf1: 0.9233 - val_macrof1: 0.9233\nEpoch 5/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6916 - single_class: 0.5106 - binary_accuracy: 0.5296 - auc_8: 0.5573 - recall: 0.7408 - precision: 0.5172 - microf1: 0.6049 - macrof1: 0.6049 - val_loss: 0.6815 - val_single_class: 0.1063 - val_binary_accuracy: 0.8806 - val_auc_8: 0.8166 - val_recall: 0.9151 - val_precision: 0.9491 - val_microf1: 0.9312 - val_macrof1: 0.9312\nEpoch 6/10\n25/25 [==============================] - 75s 3s/step - loss: 0.6877 - single_class: 0.5286 - binary_accuracy: 0.5984 - auc_8: 0.6376 - recall: 0.6981 - precision: 0.5672 - microf1: 0.6185 - macrof1: 0.6185 - val_loss: 0.6764 - val_single_class: 0.1025 - val_binary_accuracy: 0.7856 - val_auc_8: 0.7388 - val_recall: 0.8199 - val_precision: 0.9350 - val_microf1: 0.8716 - val_macrof1: 0.8716\nEpoch 7/10\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "25/25 [==============================] - 76s 3s/step - loss: 0.6812 - single_class: 0.4858 - binary_accuracy: 0.6127 - auc_8: 0.6719 - recall: 0.7148 - precision: 0.6059 - microf1: 0.6543 - macrof1: 0.6543 - val_loss: 0.6636 - val_single_class: 0.1056 - val_binary_accuracy: 0.7231 - val_auc_8: 0.7983 - val_recall: 0.7243 - val_precision: 0.9555 - val_microf1: 0.8225 - val_macrof1: 0.8225\nEpoch 8/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6685 - single_class: 0.4887 - binary_accuracy: 0.6237 - auc_8: 0.7020 - recall: 0.6656 - precision: 0.6250 - microf1: 0.6405 - macrof1: 0.6405 - val_loss: 0.6479 - val_single_class: 0.0931 - val_binary_accuracy: 0.6581 - val_auc_8: 0.8002 - val_recall: 0.6487 - val_precision: 0.9613 - val_microf1: 0.7726 - val_macrof1: 0.7726\nEpoch 9/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6306 - single_class: 0.4903 - binary_accuracy: 0.7117 - auc_8: 0.7912 - recall: 0.7299 - precision: 0.7135 - microf1: 0.7166 - macrof1: 0.7166 - val_loss: 0.6173 - val_single_class: 0.1000 - val_binary_accuracy: 0.5606 - val_auc_8: 0.7857 - val_recall: 0.5337 - val_precision: 0.9593 - val_microf1: 0.6836 - val_macrof1: 0.6836\nEpoch 10/10\n25/25 [==============================] - 76s 3s/step - loss: 0.4875 - single_class: 0.4849 - binary_accuracy: 0.8406 - auc_8: 0.9094 - recall: 0.8814 - precision: 0.8238 - microf1: 0.8499 - macrof1: 0.8499 - val_loss: 1.0718 - val_single_class: 0.1037 - val_binary_accuracy: 0.2587 - val_auc_8: 0.6989 - val_recall: 0.1751 - val_precision: 0.9876 - val_microf1: 0.2947 - val_macrof1: 0.2947\nEvaluation\n<<<<<<label 202>>>>>>>>\n12/12 [==============================] - 4s 272ms/step\nf1 : \n0.0\n------------------------------------------------------------ \nprecision : \n0.0\n------------------------------------------------------------ \nrecall : \n0.0\nModel: \"model_10\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_23 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_24 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_22 (Embedding)        (None, 1067, 128)    1024128     input_23[0][0]                   \n__________________________________________________________________________________________________\nembedding_23 (Embedding)        (None, 521, 128)     1024128     input_24[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_22 (Bidirectional (None, 100)          71600       embedding_22[0][0]               \n__________________________________________________________________________________________________\nbidirectional_23 (Bidirectional (None, 100)          71600       embedding_23[0][0]               \n__________________________________________________________________________________________________\nconcatenate_10 (Concatenate)    (None, 200)          0           bidirectional_22[0][0]           \n                                                                 bidirectional_23[0][0]           \n__________________________________________________________________________________________________\ndense_30 (Dense)                (None, 100)          20100       concatenate_10[0][0]             \n__________________________________________________________________________________________________\ndropout_20 (Dropout)            (None, 100)          0           dense_30[0][0]                   \n__________________________________________________________________________________________________\ndense_31 (Dense)                (None, 100)          10100       dropout_20[0][0]                 \n__________________________________________________________________________________________________\ndropout_21 (Dropout)            (None, 100)          0           dense_31[0][0]                   \n__________________________________________________________________________________________________\ndense_32 (Dense)                (None, 1)            101         dropout_21[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 86s 3s/step - loss: 0.6931 - single_class: 0.5146 - binary_accuracy: 0.5102 - auc_9: 0.4948 - recall: 0.2125 - precision: 0.5021 - microf1: 0.2919 - macrof1: 0.2919 - val_loss: 0.7025 - val_single_class: 0.1050 - val_binary_accuracy: 0.1050 - val_auc_9: 0.6096 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_microf1: 0.0000e+00 - val_macrof1: 0.0000e+00\nEpoch 2/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6933 - single_class: 0.5054 - binary_accuracy: 0.5070 - auc_9: 0.4971 - recall: 0.2294 - precision: 0.4936 - microf1: 0.3092 - macrof1: 0.3092 - val_loss: 0.6991 - val_single_class: 0.0950 - val_binary_accuracy: 0.2175 - val_auc_9: 0.5782 - val_recall: 0.1378 - val_precision: 0.9795 - val_microf1: 0.2384 - val_macrof1: 0.2384\nEpoch 3/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6916 - single_class: 0.5188 - binary_accuracy: 0.5501 - auc_9: 0.5413 - recall: 0.3433 - precision: 0.5502 - microf1: 0.4207 - macrof1: 0.4207 - val_loss: 0.6993 - val_single_class: 0.0887 - val_binary_accuracy: 0.2506 - val_auc_9: 0.6006 - val_recall: 0.1925 - val_precision: 0.9266 - val_microf1: 0.3164 - val_macrof1: 0.3164\nEpoch 4/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6898 - single_class: 0.5133 - binary_accuracy: 0.5598 - auc_9: 0.6038 - recall: 0.4077 - precision: 0.5689 - microf1: 0.4707 - macrof1: 0.4707 - val_loss: 0.6903 - val_single_class: 0.1150 - val_binary_accuracy: 0.4744 - val_auc_9: 0.6311 - val_recall: 0.4511 - val_precision: 0.9092 - val_microf1: 0.6003 - val_macrof1: 0.6003\nEpoch 5/10\n25/25 [==============================] - 78s 3s/step - loss: 0.6848 - single_class: 0.5233 - binary_accuracy: 0.6491 - auc_9: 0.6997 - recall: 0.6542 - precision: 0.6320 - microf1: 0.6382 - macrof1: 0.6382 - val_loss: 0.6858 - val_single_class: 0.1106 - val_binary_accuracy: 0.5444 - val_auc_9: 0.6220 - val_recall: 0.5381 - val_precision: 0.9163 - val_microf1: 0.6757 - val_macrof1: 0.6757\nEpoch 6/10\n25/25 [==============================] - 81s 3s/step - loss: 0.6776 - single_class: 0.5047 - binary_accuracy: 0.6804 - auc_9: 0.7246 - recall: 0.7710 - precision: 0.6539 - microf1: 0.7022 - macrof1: 0.7022 - val_loss: 0.6579 - val_single_class: 0.1031 - val_binary_accuracy: 0.7788 - val_auc_9: 0.7320 - val_recall: 0.8026 - val_precision: 0.9418 - val_microf1: 0.8658 - val_macrof1: 0.8658\nEpoch 7/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6400 - single_class: 0.4946 - binary_accuracy: 0.7811 - auc_9: 0.8533 - recall: 0.9406 - precision: 0.7157 - microf1: 0.8109 - macrof1: 0.8109 - val_loss: 0.5339 - val_single_class: 0.1050 - val_binary_accuracy: 0.8219 - val_auc_9: 0.7157 - val_recall: 0.8706 - val_precision: 0.9266 - val_microf1: 0.8967 - val_macrof1: 0.8967\nEpoch 8/10\n25/25 [==============================] - 75s 3s/step - loss: 0.5223 - single_class: 0.4857 - binary_accuracy: 0.8225 - auc_9: 0.9051 - recall: 0.9009 - precision: 0.7974 - microf1: 0.8384 - macrof1: 0.8384 - val_loss: 0.8769 - val_single_class: 0.1100 - val_binary_accuracy: 0.3925 - val_auc_9: 0.7214 - val_recall: 0.3334 - val_precision: 0.9534 - val_microf1: 0.4907 - val_macrof1: 0.4907\nEpoch 9/10\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "25/25 [==============================] - 75s 3s/step - loss: 0.3531 - single_class: 0.4672 - binary_accuracy: 0.8904 - auc_9: 0.9509 - recall: 0.8895 - precision: 0.9053 - microf1: 0.8955 - macrof1: 0.8955 - val_loss: 1.1178 - val_single_class: 0.0856 - val_binary_accuracy: 0.4356 - val_auc_9: 0.7706 - val_recall: 0.3915 - val_precision: 0.9801 - val_microf1: 0.5566 - val_macrof1: 0.5566\nEpoch 10/10\n25/25 [==============================] - 75s 3s/step - loss: 0.2277 - single_class: 0.4841 - binary_accuracy: 0.9254 - auc_9: 0.9756 - recall: 0.9230 - precision: 0.9328 - microf1: 0.9260 - macrof1: 0.9260 - val_loss: 1.5273 - val_single_class: 0.0975 - val_binary_accuracy: 0.3544 - val_auc_9: 0.7223 - val_recall: 0.2903 - val_precision: 0.9826 - val_microf1: 0.4457 - val_macrof1: 0.4457\nEvaluation\n<<<<<<label 100>>>>>>>>\n12/12 [==============================] - 4s 274ms/step\nf1 : \n0.05128205128205128\n------------------------------------------------------------ \nprecision : \n0.037037037037037035\n------------------------------------------------------------ \nrecall : \n0.08333333333333333\nModel: \"model_11\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_25 (InputLayer)           [(None, 1067)]       0                                            \n__________________________________________________________________________________________________\ninput_26 (InputLayer)           [(None, 521)]        0                                            \n__________________________________________________________________________________________________\nembedding_24 (Embedding)        (None, 1067, 128)    1024128     input_25[0][0]                   \n__________________________________________________________________________________________________\nembedding_25 (Embedding)        (None, 521, 128)     1024128     input_26[0][0]                   \n__________________________________________________________________________________________________\nbidirectional_24 (Bidirectional (None, 100)          71600       embedding_24[0][0]               \n__________________________________________________________________________________________________\nbidirectional_25 (Bidirectional (None, 100)          71600       embedding_25[0][0]               \n__________________________________________________________________________________________________\nconcatenate_11 (Concatenate)    (None, 200)          0           bidirectional_24[0][0]           \n                                                                 bidirectional_25[0][0]           \n__________________________________________________________________________________________________\ndense_33 (Dense)                (None, 100)          20100       concatenate_11[0][0]             \n__________________________________________________________________________________________________\ndropout_22 (Dropout)            (None, 100)          0           dense_33[0][0]                   \n__________________________________________________________________________________________________\ndense_34 (Dense)                (None, 100)          10100       dropout_22[0][0]                 \n__________________________________________________________________________________________________\ndropout_23 (Dropout)            (None, 100)          0           dense_34[0][0]                   \n__________________________________________________________________________________________________\ndense_35 (Dense)                (None, 1)            101         dropout_23[0][0]                 \n==================================================================================================\nTotal params: 2,221,757\nTrainable params: 2,221,757\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 88s 3s/step - loss: 0.6922 - single_class: 0.4976 - binary_accuracy: 0.5302 - auc_10: 0.5397 - recall: 0.5172 - precision: 0.5364 - microf1: 0.5211 - macrof1: 0.5211 - val_loss: 0.6920 - val_single_class: 0.1088 - val_binary_accuracy: 0.5719 - val_auc_10: 0.5887 - val_recall: 0.5669 - val_precision: 0.9232 - val_microf1: 0.7003 - val_macrof1: 0.7003\nEpoch 2/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6912 - single_class: 0.4939 - binary_accuracy: 0.5497 - auc_10: 0.5488 - recall: 0.6399 - precision: 0.5485 - microf1: 0.5852 - macrof1: 0.5852 - val_loss: 0.6910 - val_single_class: 0.1131 - val_binary_accuracy: 0.5331 - val_auc_10: 0.4914 - val_recall: 0.5477 - val_precision: 0.8788 - val_microf1: 0.6732 - val_macrof1: 0.6732\nEpoch 3/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6884 - single_class: 0.5062 - binary_accuracy: 0.5873 - auc_10: 0.6124 - recall: 0.6404 - precision: 0.5763 - microf1: 0.6006 - macrof1: 0.6006 - val_loss: 0.7025 - val_single_class: 0.0881 - val_binary_accuracy: 0.3281 - val_auc_10: 0.5437 - val_recall: 0.2814 - val_precision: 0.9424 - val_microf1: 0.4315 - val_macrof1: 0.4315\nEpoch 4/10\n25/25 [==============================] - 76s 3s/step - loss: 0.6816 - single_class: 0.5024 - binary_accuracy: 0.6370 - auc_10: 0.6960 - recall: 0.6428 - precision: 0.6338 - microf1: 0.6365 - macrof1: 0.6365 - val_loss: 0.7092 - val_single_class: 0.1125 - val_binary_accuracy: 0.4356 - val_auc_10: 0.6284 - val_recall: 0.3796 - val_precision: 0.9614 - val_microf1: 0.5409 - val_macrof1: 0.5409\nEpoch 5/10\n25/25 [==============================] - 77s 3s/step - loss: 0.6583 - single_class: 0.4962 - binary_accuracy: 0.7120 - auc_10: 0.8016 - recall: 0.6477 - precision: 0.7559 - microf1: 0.6947 - macrof1: 0.6947 - val_loss: 0.7754 - val_single_class: 0.1025 - val_binary_accuracy: 0.2631 - val_auc_10: 0.6411 - val_recall: 0.1881 - val_precision: 0.9475 - val_microf1: 0.3110 - val_macrof1: 0.3110\nEpoch 6/10\n25/25 [==============================] - 75s 3s/step - loss: 0.5624 - single_class: 0.5280 - binary_accuracy: 0.8322 - auc_10: 0.8923 - recall: 0.7898 - precision: 0.8474 - microf1: 0.8110 - macrof1: 0.8110 - val_loss: 0.9324 - val_single_class: 0.0862 - val_binary_accuracy: 0.3388 - val_auc_10: 0.6809 - val_recall: 0.2828 - val_precision: 0.9750 - val_microf1: 0.4354 - val_macrof1: 0.4354\nEpoch 7/10\n25/25 [==============================] - 74s 3s/step - loss: 0.3928 - single_class: 0.4588 - binary_accuracy: 0.9131 - auc_10: 0.9561 - recall: 0.9089 - precision: 0.9322 - microf1: 0.9182 - macrof1: 0.9182 - val_loss: 1.3555 - val_single_class: 0.0906 - val_binary_accuracy: 0.3438 - val_auc_10: 0.6657 - val_recall: 0.2818 - val_precision: 0.9853 - val_microf1: 0.4369 - val_macrof1: 0.4369\nEpoch 8/10\n25/25 [==============================] - 73s 3s/step - loss: 0.2452 - single_class: 0.4917 - binary_accuracy: 0.9331 - auc_10: 0.9758 - recall: 0.9346 - precision: 0.9340 - microf1: 0.9337 - macrof1: 0.9337 - val_loss: 1.6902 - val_single_class: 0.0988 - val_binary_accuracy: 0.3438 - val_auc_10: 0.6454 - val_recall: 0.2736 - val_precision: 0.9947 - val_microf1: 0.4257 - val_macrof1: 0.4257\nEpoch 9/10\n25/25 [==============================] - 74s 3s/step - loss: 0.1663 - single_class: 0.4903 - binary_accuracy: 0.9673 - auc_10: 0.9901 - recall: 0.9729 - precision: 0.9631 - microf1: 0.9676 - macrof1: 0.9676 - val_loss: 2.1643 - val_single_class: 0.0881 - val_binary_accuracy: 0.3363 - val_auc_10: 0.6784 - val_recall: 0.2750 - val_precision: 0.9909 - val_microf1: 0.4287 - val_macrof1: 0.4287\nEpoch 10/10\n25/25 [==============================] - 73s 3s/step - loss: 0.1093 - single_class: 0.5187 - binary_accuracy: 0.9665 - auc_10: 0.9951 - recall: 0.9734 - precision: 0.9579 - microf1: 0.9648 - macrof1: 0.9648 - val_loss: 2.8183 - val_single_class: 0.0894 - val_binary_accuracy: 0.1675 - val_auc_10: 0.6597 - val_recall: 0.0875 - val_precision: 0.9730 - val_microf1: 0.1590 - val_macrof1: 0.1590\nEvaluation\n<<<<<<label 417>>>>>>>>\n12/12 [==============================] - 4s 268ms/step\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "f1 : \n0.06666666666666667\n------------------------------------------------------------ \nprecision : \n0.09090909090909091\n------------------------------------------------------------ \nrecall : \n0.05263157894736842\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Bilstm.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}